{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means clustering \n",
    "\n",
    "\n",
    "\n",
    "1.Choose the number of clusters (k). This is a critical step, as the number of clusters will determine the granularity of the clustering results.\n",
    "\n",
    "2.Randomly initialize the cluster centroids. This can be done by randomly selecting k data points from the data set.\n",
    "\n",
    "3.Assign each data point to the cluster whose centroid is closest to it. This can be done using a distance metric, such as the \n",
    "Euclidean distance or the Manhattan distance.\n",
    "\n",
    "4.Recalculate the centroids of each cluster. The centroid of a cluster is the mean value of the data points in that cluster.\n",
    "\n",
    "5.Repeat steps 3 and 4 until the centroids no longer change or until a maximum number of iterations is reached.\n",
    "\n",
    "\n",
    "some of the advantages of k-means clustering:\n",
    "\n",
    "It is relatively simple to implement and understand.\n",
    "It can be used to cluster data points in a variety of dimensions.\n",
    "It is relatively efficient, especially for large data sets.\n",
    "\n",
    "some of the disadvantages of k-means clustering:\n",
    "\n",
    "The choice of the number of clusters (k) can be arbitrary.\n",
    "The algorithm can be sensitive to the initial choice of the cluster centroids.\n",
    "The algorithm can be trapped in local minima.\n",
    "\n",
    "Common Performance Measures used for Clustering:\n",
    "\n",
    "1.Within-cluster sum of squares (WCSS): This is the sum of the squared distances between each data point and the centroid of its cluster. A lower WCSS indicates that the data points within each cluster are more tightly clustered together.\n",
    "\n",
    "2.Between-cluster sum of squares (BCSS): This is the sum of the squared distances between each cluster centroid and the overall mean of the data set. A higher BCSS indicates that the cluster centroids are more well-separated from each other.\n",
    "\n",
    "3.Homogeneity: This measures the similarity of data points within the same cluster. A higher homogeneity score indicates that the data points within each cluster are more similar to each other. Intra-Clsuter Vairance\n",
    "\n",
    "4.Completeness: This measures the similarity of data points to the cluster centroids. A higher completeness score indicates that the data points are more similar to the cluster centroids of their respective clusters. Inter-Cluster Variance\n",
    "\n",
    "5.Silhouette coefficient: This is a measure of how well each data point is assigned to its cluster. A higher silhouette coefficient indicates that the data point is more well-clustered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def kmeans(data, k, max_iter):\n",
    "    random.seed(9001)\n",
    "    centroids = []\n",
    "    for _ in range(k):\n",
    "        centroids.append([random.randint(0, 100), random.randint(0, 100)])\n",
    "\n",
    "    labels = []\n",
    "    for i in range(len(data)):\n",
    "        distances = []\n",
    "        for j in range(k):\n",
    "            distances.append(distance(data[i], centroids[j]))\n",
    "        labels.append(distances.index(min(distances)))\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        new_centroids = []\n",
    "        for i in range(k):\n",
    "            new_centroids.append([0, 0])\n",
    "            for j in range(len(data)):\n",
    "                if labels[j] == i:\n",
    "                    new_centroids[i][0] += data[j][0]\n",
    "                    new_centroids[i][1] += data[j][1]\n",
    "            new_centroids[i][0] /= len(data[labels == i])\n",
    "            new_centroids[i][1] /= len(data[labels == i])\n",
    "\n",
    "        for i in range(k):\n",
    "            if new_centroids[i] != centroids[i]:\n",
    "                centroids = new_centroids\n",
    "\n",
    "    return labels\n",
    "\n",
    "def distance(p1, p2):\n",
    "    return ((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2)**0.5\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 1, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "data = [[10, 10], [50, 50], [30, 30], [70, 70], [90, 90]]\n",
    "\n",
    "labels = kmeans(data, 4, 100)\n",
    "\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
